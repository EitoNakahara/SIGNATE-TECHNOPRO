{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "k6fwAoTJM6C9",
        "1Vj3FOtIMwVm",
        "2u1PXeD9n4X5",
        "wr0HntSeZkSs",
        "7bu39caaZ8vR",
        "wMs0JLFENDu9",
        "WCvI0uL0bWlK",
        "Org1jUADSQ1n"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9wQDsmlBZI0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3faf3a18-440b-4932-8c0c-5fb93bd06d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install colorama\n",
        "!cp /content/drive/MyDrive/DataCompetition/TECHNOPRO/dataset/train.zip .\n",
        "!cp /content/drive/MyDrive/DataCompetition/TECHNOPRO/dataset/test.zip .\n",
        "!unzip train.zip\n",
        "!unzip test.zip"
      ],
      "metadata": {
        "id": "tdvtKF0Xa23d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "k6fwAoTJM6C9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "debqpYL2YCVl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd4ae55e-4e60-40f4-a4f9-3d31ed695089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: grad-cam in /usr/local/lib/python3.10/dist-packages (1.4.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from grad-cam) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from grad-cam) (9.4.0)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from grad-cam) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from grad-cam) (0.15.2+cu118)\n",
            "Requirement already satisfied: ttach in /usr/local/lib/python3.10/dist-packages (from grad-cam) (0.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from grad-cam) (4.66.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from grad-cam) (4.8.0.76)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from grad-cam) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from grad-cam) (1.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.1->grad-cam) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.1->grad-cam) (16.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.8.2->grad-cam) (2.31.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam) (1.11.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->grad-cam) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.1->grad-cam) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.1->grad-cam) (1.3.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.7)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.17.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Requirement already satisfied: pytorch_optimizer in /usr/local/lib/python3.10/dist-packages (2.11.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch_optimizer) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from pytorch_optimizer) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->pytorch_optimizer) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->pytorch_optimizer) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->pytorch_optimizer) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->pytorch_optimizer) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->pytorch_optimizer) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->pytorch_optimizer) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->pytorch_optimizer) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->pytorch_optimizer) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->pytorch_optimizer) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->pytorch_optimizer) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install grad-cam\n",
        "!pip install timm\n",
        "!pip install pytorch_optimizer\n",
        "\n",
        "import ttach as tta\n",
        "\n",
        "import os, shutil\n",
        "\n",
        "#必要なライブラリのインポート\n",
        "import re, gc, sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "\n",
        "import warnings, random\n",
        "import cv2\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import timm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import lr_scheduler\n",
        "from pytorch_optimizer import Ranger21\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "from torch.cuda.amp import GradScaler\n",
        "\n",
        "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "\n",
        "import yaml\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "\n",
        "from colorama import Fore, Back, Style\n",
        "b_ = Fore.BLUE\n",
        "y_ = Fore.YELLOW\n",
        "sr_ = Style.RESET_ALL"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## パラメータの設定"
      ],
      "metadata": {
        "id": "1Vj3FOtIMwVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ARGS = {'DATA_DIR': '/content/drive/MyDrive/DataCompetition/TECHNOPRO/dataset',\n",
        "  # 'OUT_DIR': '/content/drive/MyDrive/DataCompetition/TECHNOPRO/Vit',\n",
        "  'OUT_DIR': '/content/drive/MyDrive/DataCompetition/TECHNOPRO/Swin',\n",
        "  # 'OUT_DIR': '/content/drive/MyDrive/DataCompetition/TECHNOPRO/eva02',\n",
        "  'model_name': 'vit_l_16',\n",
        "  'n_fold': 5,\n",
        "  'epochs': 4,\n",
        "  'criterion': 'CrossEntropy',\n",
        "  'image_size': (384, 384),\n",
        "  'train_batch_size': 8, # 元は16\n",
        "  'test_batch_size': 32,\n",
        "  'seed': 2023,\n",
        "  'optimizer': 'AdamW',\n",
        "  'learning_rate': 1e-05,\n",
        "  'scheduler': 'CosineAnnealingLR',\n",
        "  'min_lr': 1e-06,\n",
        "  'T_max': 500,\n",
        "  'n_accumulate': 1,\n",
        "  'clip_grad_norm': 'None',\n",
        "  'apex': True,\n",
        "  'num_classes': 2,\n",
        "  'device': torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  }\n",
        "ARGS"
      ],
      "metadata": {
        "id": "U71zKHyzmQYI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d6458f1-fc25-400e-e3fd-62f30b67cf06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DATA_DIR': '/content/drive/MyDrive/DataCompetition/TECHNOPRO/dataset',\n",
              " 'OUT_DIR': '/content/drive/MyDrive/DataCompetition/TECHNOPRO/Swin',\n",
              " 'model_name': 'vit_l_16',\n",
              " 'n_fold': 5,\n",
              " 'epochs': 4,\n",
              " 'criterion': 'CrossEntropy',\n",
              " 'image_size': (384, 384),\n",
              " 'train_batch_size': 8,\n",
              " 'test_batch_size': 32,\n",
              " 'seed': 2023,\n",
              " 'optimizer': 'AdamW',\n",
              " 'learning_rate': 1e-05,\n",
              " 'scheduler': 'CosineAnnealingLR',\n",
              " 'min_lr': 1e-06,\n",
              " 'T_max': 500,\n",
              " 'n_accumulate': 1,\n",
              " 'clip_grad_norm': 'None',\n",
              " 'apex': True,\n",
              " 'num_classes': 2,\n",
              " 'device': device(type='cuda', index=0)}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_logger(filename):\n",
        "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
        "    logger = getLogger(__name__)\n",
        "    logger.setLevel(INFO)\n",
        "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
        "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
        "    logger.addHandler(handler2)\n",
        "    return logger\n",
        "\n",
        "#再現性を出すために必要な関数となります\n",
        "def worker_init_fn(worker_id):\n",
        "    torch.manual_seed(worker_id)\n",
        "    random.seed(worker_id)\n",
        "    np.random.seed(worker_id)\n",
        "    torch.cuda.manual_seed(worker_id)\n",
        "    os.environ['PYTHONHASHSEED'] = str(worker_id)\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
        "    This is for REPRODUCIBILITY.'''\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "\n",
        "LOGGER = get_logger(ARGS['OUT_DIR']+'train')\n",
        "set_seed(ARGS[\"seed\"])"
      ],
      "metadata": {
        "id": "GnpgLiIkY7fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Folds"
      ],
      "metadata": {
        "id": "2u1PXeD9n4X5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_folds(data, num_splits, seed):\n",
        "    data[\"kfold\"] = -1\n",
        "\n",
        "    mskf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=seed)\n",
        "    labels = [\"label\"]\n",
        "    data_labels = data[labels].values\n",
        "\n",
        "    for f, (t_, v_) in enumerate(mskf.split(data, data_labels)):\n",
        "        data.loc[v_, \"kfold\"] = f\n",
        "\n",
        "    return data\n",
        "\n",
        "train = pd.read_csv(f\"{ARGS['DATA_DIR']}/train.csv\")\n",
        "train = create_folds(train, num_splits=ARGS[\"n_fold\"], seed=ARGS[\"seed\"])\n",
        "print(\"Folds created successfully\")\n",
        "\n",
        "train.head()"
      ],
      "metadata": {
        "id": "PO-efyDvY7nu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8613140a-fbe1-40df-df41-5784d9b9739c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folds created successfully\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  image_name  label  kfold\n",
              "0   0000.png      0      0\n",
              "1   0001.png      1      3\n",
              "2   0002.png      1      2\n",
              "3   0003.png      1      1\n",
              "4   0004.png      0      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ace47b90-ea60-44de-9a7f-8dad5c4fbeb8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>label</th>\n",
              "      <th>kfold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000.png</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0001.png</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0002.png</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0003.png</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0004.png</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ace47b90-ea60-44de-9a7f-8dad5c4fbeb8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ace47b90-ea60-44de-9a7f-8dad5c4fbeb8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ace47b90-ea60-44de-9a7f-8dad5c4fbeb8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a0958fac-4fc4-4bf0-93be-4dac4ce5d279\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a0958fac-4fc4-4bf0-93be-4dac4ce5d279')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a0958fac-4fc4-4bf0-93be-4dac4ce5d279 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"label\"].value_counts()"
      ],
      "metadata": {
        "id": "oQNg8cPJY7sr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d9cc851-4eb0-4b4f-a1a4-49e2e8c83365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1182\n",
              "0     994\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['kfold'].value_counts()"
      ],
      "metadata": {
        "id": "l05WcTgMn9-A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ec43710-1d85-4140-9dee-3243368d6b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    436\n",
              "3    435\n",
              "2    435\n",
              "1    435\n",
              "4    435\n",
              "Name: kfold, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 画像の読み込みと前処理"
      ],
      "metadata": {
        "id": "wr0HntSeZkSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, df, transform, data_type):\n",
        "        self.df = df\n",
        "        self.data_type = data_type\n",
        "        self.images = []\n",
        "\n",
        "        if self.data_type == \"train\":\n",
        "            self.image_paths = df['image_name']\n",
        "            self.labels = df['label']\n",
        "        if self.data_type == \"test\":\n",
        "            self.image_paths = df[0]\n",
        "\n",
        "        self.transform= transform\n",
        "\n",
        "        # Load images into RAM beforehand\n",
        "        for image_path in self.image_paths:\n",
        "            if self.data_type == \"train\":\n",
        "                image = cv2.imread(f\"/content/train/{image_path}\")\n",
        "            if self.data_type == \"test\":\n",
        "                image = cv2.imread(f\"/content/test/{image_path}\")\n",
        "\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            self.images.append(image)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        image = self.images[index]\n",
        "\n",
        "        image = self.transform(image=image)[\"image\"]\n",
        "\n",
        "        if self.data_type == \"train\":\n",
        "            label = self.labels[index]\n",
        "            label = torch.tensor(label, dtype=torch.long)\n",
        "            return image, label\n",
        "\n",
        "        if self.data_type == \"test\":\n",
        "            return image"
      ],
      "metadata": {
        "id": "EgO_OlmXr11j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as albu\n",
        "from albumentations.pytorch import transforms as AT\n",
        "\n",
        "# Augumentation用\n",
        "image_transform = albu.Compose([\n",
        "    #albu.Resize(ARGS[\"image_size\"][0], ARGS[\"image_size\"][1]),\n",
        "    albu.RandomResizedCrop(ARGS[\"image_size\"][0], ARGS[\"image_size\"][1]),\n",
        "    albu.Flip(p=0.5),\n",
        "    albu.RandomRotate90(p=0.5),\n",
        "    albu.Blur(blur_limit=7, always_apply=False, p=0.5),\n",
        "    #albu.RandomBrightnessContrast(p=0.3),\n",
        "    #albu.RandomGamma(gamma_limit=(85, 115), p=0.3),\n",
        "    #albu.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.10, rotate_limit=45, p=0.5),\n",
        "    albu.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    AT.ToTensorV2()\n",
        "])"
      ],
      "metadata": {
        "id": "fsBvDpfZZmQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習用関数定義"
      ],
      "metadata": {
        "id": "7bu39caaZ8vR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, optimizer, train_loader, device, epoch):\n",
        "    model.train()\n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "    running_score = []\n",
        "    running_score_y = []\n",
        "    scaler = GradScaler(enabled=ARGS[\"apex\"])\n",
        "\n",
        "    train_loss = []\n",
        "    bar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
        "    for step, (images, targets) in bar:\n",
        "      images = images.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      batch_size = targets.size(0)\n",
        "      with torch.cuda.amp.autocast(enabled=ARGS[\"apex\"]):\n",
        "          outputs = model(images)\n",
        "          loss = criterion(ARGS, outputs, targets)\n",
        "\n",
        "      scaler.scale(loss).backward()\n",
        "\n",
        "      if ARGS[\"clip_grad_norm\"] != \"None\":\n",
        "          grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), ARGS[\"clip_grad_norm\"])\n",
        "      else:\n",
        "          grad_norm = None\n",
        "\n",
        "      scaler.step(optimizer)\n",
        "      scaler.update()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      if scheduler is not None:\n",
        "          scheduler.step()\n",
        "\n",
        "      train_loss.append(loss.item())\n",
        "\n",
        "      running_loss += (loss.item() * batch_size)\n",
        "      dataset_size += batch_size\n",
        "\n",
        "      epoch_loss = running_loss / dataset_size\n",
        "\n",
        "      running_score.append(outputs.detach().cpu().numpy())\n",
        "      running_score_y.append(targets.detach().cpu().numpy())\n",
        "\n",
        "      score = get_score(running_score_y, running_score)\n",
        "\n",
        "      bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n",
        "                      Train_Acc=score[0],\n",
        "                      Train_Auc=score[1],\n",
        "                      LR=optimizer.param_groups[0]['lr']\n",
        "                      )\n",
        "    gc.collect()\n",
        "    return epoch_loss, score"
      ],
      "metadata": {
        "id": "pDXcr9owsjgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@torch.no_grad()\n",
        "def valid_one_epoch(args, model, optimizer, valid_loader, epoch):\n",
        "    model.eval()\n",
        "\n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "    preds = []\n",
        "    valid_targets = []\n",
        "    softmax = nn.Softmax()\n",
        "\n",
        "    bar = tqdm(enumerate(valid_loader), total=len(valid_loader))\n",
        "    for step, (images, targets) in enumerate(valid_loader):\n",
        "      images = images.to(args[\"device\"])\n",
        "      targets = targets.to(args[\"device\"])\n",
        "      batch_size = targets.size(0)\n",
        "      with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        predict = outputs.softmax(dim=1)\n",
        "        loss = criterion(args, outputs, targets)\n",
        "\n",
        "      running_loss += (loss.item() * batch_size)\n",
        "      dataset_size += batch_size\n",
        "\n",
        "      epoch_loss = running_loss / dataset_size\n",
        "\n",
        "      preds.append(predict.detach().cpu().numpy())\n",
        "      valid_targets.append(targets.detach().cpu().numpy())\n",
        "\n",
        "      if len(set(np.concatenate(valid_targets))) == 1:\n",
        "          continue\n",
        "      score = get_score(valid_targets, preds)\n",
        "\n",
        "      bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n",
        "                      Valid_Acc=score[0],\n",
        "                      Valid_Auc=score[1],\n",
        "                      LR=optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    return epoch_loss, preds, valid_targets, score\n"
      ],
      "metadata": {
        "id": "MjXWVj3ZJW_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_fold(model, optimizer, schedulerr, device, num_epochs, fold):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
        "\n",
        "    start = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_epoch_score = np.inf\n",
        "    best_prediction = None\n",
        "\n",
        "    best_score = -np.inf\n",
        "    for epoch in range(1, 1+num_epochs):\n",
        "      train_epoch_loss, train_score = train_one_epoch(model, optimizer,\n",
        "                                              train_loader=train_loader,\n",
        "                                              device=device, epoch=epoch)\n",
        "\n",
        "      train_acc, train_auc = train_score\n",
        "\n",
        "      val_epoch_loss, predictions, valid_targets, valid_score = valid_one_epoch(ARGS,\n",
        "                                                                                model,\n",
        "                                                                                optimizer,\n",
        "                                                                                valid_loader,\n",
        "                                                                                epoch=epoch)\n",
        "      valid_acc, valid_auc = valid_score\n",
        "\n",
        "\n",
        "      LOGGER.info(f'Epoch {epoch} - avg_train_loss: {train_epoch_loss:.4f}  avg_val_loss: {val_epoch_loss:.4f}')\n",
        "      LOGGER.info(f'Epoch {epoch} - Train Acc: {train_acc:.4f}  Train Auc: {train_auc:.4f}  Valid Acc: {valid_acc:.4f}  Valid Auc: {valid_auc:.4f}')\n",
        "\n",
        "      if valid_auc >= best_score:\n",
        "        best_score = valid_auc\n",
        "\n",
        "        print(f\"{b_}Validation Score Improved ({best_epoch_score} ---> {valid_auc})\")\n",
        "        best_epoch_score = valid_auc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        # PATH = f\"Score-Fold-{fold}.bin\"\n",
        "        PATH = ARGS[\"OUT_DIR\"] + f\"/Score-Fold-{fold}.bin\"\n",
        "        torch.save(model.state_dict(), PATH)\n",
        "        # Save a model file from the current directory\n",
        "        print(f\"Model Saved{sr_}\")\n",
        "\n",
        "        best_prediction = np.concatenate(predictions, axis=0)[:,1]\n",
        "\n",
        "    end = time.time()\n",
        "    time_elapsed = end - start\n",
        "\n",
        "    LOGGER.info('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
        "    LOGGER.info(\"Best Score: {:.4f}\".format(best_epoch_score))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, best_prediction, valid_targets"
      ],
      "metadata": {
        "id": "4XYmBp13aDAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モデルや損失関数、最適化関数等の定義"
      ],
      "metadata": {
        "id": "wMs0JLFENDu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(args):\n",
        "    model = timm.create_model('swin_large_patch4_window12_384.ms_in22k_ft_in1k', pretrained=True, num_classes=2)\n",
        "    return model\n",
        "\n",
        "# def create_model(args):\n",
        "#     model = timm.create_model('tf_efficientnetv2_m.in21k_ft_in1k', pretrained=True, num_classes=2)\n",
        "#     return model\n",
        "\n",
        "# def create_model(args):\n",
        "#     model = timm.create_model('eva02_base_patch14_224.mim_in22k', pretrained=True, num_classes=2)\n",
        "#     return model\n",
        "\n",
        "# def create_model(args):\n",
        "#     model = models.vit_l_16(weights=models.vision_transformer.ViT_L_16_Weights.IMAGENET1K_SWAG_LINEAR_V1)\n",
        "#     model.heads[0] = torch.nn.Linear(in_features=model.heads[0].in_features, out_features=args[\"num_classes\"], bias=True)\n",
        "#     return model\n",
        "\n",
        "#ViT_B_16_Weights.IMAGENET1K_SWAG_E2E_V1\n",
        "\n",
        "# def create_model(args):\n",
        "#     model = models.vit_l_16(weights=models.vision_transformer.ViT_L_16_Weights.IMAGENET1K_SWAG_E2E_V1)\n",
        "#     model.heads[0] = torch.nn.Linear(in_features=model.heads[0].in_features, out_features=args[\"num_classes\"], bias=True)\n",
        "#     return model\n",
        "\n",
        "def criterion(args, outputs, labels, class_weights=None):\n",
        "    if args['criterion'] == 'CrossEntropy':\n",
        "      return nn.CrossEntropyLoss(weight=class_weights).to(args[\"device\"])(outputs, labels)\n",
        "    elif args['criterion'] == \"None\":\n",
        "        return None\n",
        "\n",
        "def fetch_optimizer(optimizer_parameters, lr, betas, optimizer_name=\"Adam\"):\n",
        "    if optimizer_name == \"Adam\":\n",
        "        optimizer = optim.Adam(optimizer_parameters, lr=lr)\n",
        "    elif optimizer_name == \"AdamW\":\n",
        "        optimizer = optim.AdamW(optimizer_parameters, lr=lr, betas=betas)\n",
        "    return optimizer\n",
        "\n",
        "def fetch_scheduler(args, train_size, optimizer):\n",
        "\n",
        "    if args['scheduler'] == 'CosineAnnealingLR':\n",
        "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=args['T_max'],\n",
        "                                                   eta_min=args['min_lr'])\n",
        "    elif args['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
        "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=args['T_0'],\n",
        "                                                             eta_min=args['min_lr'])\n",
        "    elif args['scheduler'] == \"None\":\n",
        "        scheduler = None\n",
        "\n",
        "    return scheduler\n",
        "\n",
        "def get_score(y_trues, y_preds):\n",
        "\n",
        "    predict_list, targets_list = np.concatenate(y_preds, axis=0), np.concatenate(y_trues)\n",
        "    predict_list_proba = predict_list.copy()[:, 1]\n",
        "    predict_list = predict_list.argmax(axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(predict_list, targets_list)\n",
        "    auc_score = roc_auc_score(targets_list, predict_list_proba)\n",
        "\n",
        "    return (accuracy, auc_score)\n",
        "\n",
        "def prepare_loaders(args, train, image_transform, fold):\n",
        "    df_train = train[train.kfold != fold].reset_index(drop=True)\n",
        "    df_valid = train[train.kfold == fold].reset_index(drop=True)\n",
        "\n",
        "    train_dataset = CustomDataset(df_train, image_transform, data_type=\"train\")\n",
        "    valid_dataset = CustomDataset(df_valid, image_transform, data_type=\"train\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=args['train_batch_size'],\n",
        "                              worker_init_fn=worker_init_fn(args[\"seed\"]),\n",
        "                              num_workers=4,\n",
        "                              shuffle=True, pin_memory=True, drop_last=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=args['test_batch_size'],\n",
        "                              num_workers=4,\n",
        "                              shuffle=False, pin_memory=True)\n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "metadata": {
        "id": "0wBVejHmfU2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_copy = train.copy()\n",
        "LOGGER.info(ARGS)\n",
        "for fold in range(0, ARGS['n_fold']):\n",
        "    print(f\"{y_}====== Fold: {fold} ======{sr_}\")\n",
        "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
        "\n",
        "    # Create Dataloaders\n",
        "    train_loader, valid_loader = prepare_loaders(args=ARGS, train=train, image_transform=image_transform, fold=fold)\n",
        "\n",
        "    model = create_model(ARGS)\n",
        "    model = model.to(ARGS[\"device\"])\n",
        "\n",
        "    #損失関数・最適化関数の定義\n",
        "    optimizer = fetch_optimizer(model.parameters(), optimizer_name=ARGS[\"optimizer\"], lr=ARGS[\"learning_rate\"], betas=(0.9, 0.999))\n",
        "\n",
        "    scheduler = fetch_scheduler(args=ARGS, train_size=len(train_loader), optimizer=optimizer)\n",
        "\n",
        "    model, predictions, targets = one_fold(model, optimizer, scheduler, device=ARGS[\"device\"], num_epochs=ARGS[\"epochs\"], fold=fold)\n",
        "\n",
        "    train_copy.loc[train_copy[train_copy.kfold == fold].index, \"oof\"] = predictions\n",
        "\n",
        "    del model, train_loader, valid_loader\n",
        "    _ = gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    print()\n",
        "\n",
        "scores = roc_auc_score(train_copy[\"label\"].values, train_copy[\"oof\"].values)\n",
        "LOGGER.info(f\"========== CV ==========\")\n",
        "LOGGER.info(f\"CV: {scores:.4f}\")"
      ],
      "metadata": {
        "id": "sjOsaXWeCwf-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ddc1021-6fe2-4e14-fdb0-3bc5c0eb5021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:{'DATA_DIR': '/content/drive/MyDrive/DataCompetition/TECHNOPRO/dataset', 'OUT_DIR': '/content/drive/MyDrive/DataCompetition/TECHNOPRO/Swin', 'model_name': 'vit_l_16', 'n_fold': 5, 'epochs': 4, 'criterion': 'CrossEntropy', 'image_size': (384, 384), 'train_batch_size': 8, 'test_batch_size': 32, 'seed': 2023, 'optimizer': 'AdamW', 'learning_rate': 1e-05, 'scheduler': 'CosineAnnealingLR', 'min_lr': 1e-06, 'T_max': 500, 'n_accumulate': 1, 'clip_grad_norm': 'None', 'apex': True, 'num_classes': 2, 'device': device(type='cuda', index=0)}\n",
            "INFO:__main__:========== fold: 0 training ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m====== Fold: 0 ======\u001b[0m\n",
            "[INFO] Using GPU: Tesla T4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 217/217 [02:32<00:00,  1.42it/s, Epoch=1, LR=6.43e-6, Train_Acc=0.662, Train_Auc=0.713, Train_Loss=0.608]\n",
            "  0%|          | 0/14 [00:34<?, ?it/s, Epoch=1, LR=6.43e-6, Valid_Acc=0.72, Valid_Auc=0.772, Valid_Loss=0.567]\n",
            "INFO:__main__:Epoch 1 - avg_train_loss: 0.6082  avg_val_loss: 0.5666\n",
            "INFO:__main__:Epoch 1 - Train Acc: 0.6624  Train Auc: 0.7125  Valid Acc: 0.7202  Valid Auc: 0.7715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mValidation Score Improved (inf ---> 0.7715370099442359)\n",
            "Model Saved\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 217/217 [02:33<00:00,  1.42it/s, Epoch=2, LR=1.38e-6, Train_Acc=0.762, Train_Auc=0.824, Train_Loss=0.492]\n",
            "  0%|          | 0/14 [00:33<?, ?it/s, Epoch=2, LR=1.38e-6, Valid_Acc=0.739, Valid_Auc=0.82, Valid_Loss=0.507]\n",
            "INFO:__main__:Epoch 2 - avg_train_loss: 0.4919  avg_val_loss: 0.5068\n",
            "INFO:__main__:Epoch 2 - Train Acc: 0.7615  Train Auc: 0.8244  Valid Acc: 0.7385  Valid Auc: 0.8199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mValidation Score Improved (0.7715370099442359 ---> 0.8199011937323749)\n",
            "Model Saved\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 217/217 [02:34<00:00,  1.41it/s, Epoch=3, LR=2.88e-6, Train_Acc=0.787, Train_Auc=0.847, Train_Loss=0.464]\n",
            "  0%|          | 0/14 [00:33<?, ?it/s, Epoch=3, LR=2.88e-6, Valid_Acc=0.761, Valid_Auc=0.846, Valid_Loss=0.479]\n",
            "INFO:__main__:Epoch 3 - avg_train_loss: 0.4639  avg_val_loss: 0.4792\n",
            "INFO:__main__:Epoch 3 - Train Acc: 0.7874  Train Auc: 0.8467  Valid Acc: 0.7615  Valid Auc: 0.8463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mValidation Score Improved (0.8199011937323749 ---> 0.8462565994529611)\n",
            "Model Saved\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 217/217 [02:32<00:00,  1.42it/s, Epoch=4, LR=8.54e-6, Train_Acc=0.789, Train_Auc=0.86, Train_Loss=0.44]\n",
            "  0%|          | 0/14 [00:33<?, ?it/s, Epoch=4, LR=8.54e-6, Valid_Acc=0.766, Valid_Auc=0.843, Valid_Loss=0.493]\n",
            "INFO:__main__:Epoch 4 - avg_train_loss: 0.4402  avg_val_loss: 0.4926\n",
            "INFO:__main__:Epoch 4 - Train Acc: 0.7886  Train Auc: 0.8595  Valid Acc: 0.7661  Valid Auc: 0.8430\n",
            "INFO:__main__:Training complete in 0h 12m 50s\n",
            "INFO:__main__:Best Score: 0.8463\n",
            "INFO:__main__:========== fold: 1 training ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[33m====== Fold: 1 ======\u001b[0m\n",
            "[INFO] Using GPU: Tesla T4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 217/217 [02:32<00:00,  1.42it/s, Epoch=1, LR=6.43e-6, Train_Acc=0.681, Train_Auc=0.709, Train_Loss=0.612]\n",
            "  0%|          | 0/14 [00:05<?, ?it/s, Epoch=1, LR=6.43e-6, Valid_Acc=0.719, Valid_Auc=0.874, Valid_Loss=0.461]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OOF\n",
        "train_copy.to_csv(ARGS['OUT_DIR'] + f'/oof.csv', index=False)"
      ],
      "metadata": {
        "id": "-ApHBsNpSiuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 結果の表示"
      ],
      "metadata": {
        "id": "WCvI0uL0bWlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sample_submit.csvを読み込みます\n",
        "submit = pd.read_csv(f\"{ARGS['DATA_DIR']}/sample_submit.csv\", header=None)\n",
        "submit.head()"
      ],
      "metadata": {
        "id": "BWWQvQAMbaAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "Org1jUADSQ1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test用のデータ拡張\n",
        "image_transform_test = albu.Compose([\n",
        "    albu.Resize(ARGS[\"image_size\"][0], ARGS[\"image_size\"][1]),\n",
        "    albu.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    AT.ToTensorV2 ()\n",
        "    ])\n",
        "test_dataset = CustomDataset(submit, image_transform_test, data_type=\"test\")\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "OFk1tFqxbd55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TTA(Test-Time Augmentation)\n",
        "transforms = tta.Compose(\n",
        "    [\n",
        "        tta.HorizontalFlip(),\n",
        "        tta.VerticalFlip(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "@torch.no_grad()\n",
        "def valid_fn(model, dataloader, device):\n",
        "    model.eval()\n",
        "    tta_model = tta.ClassificationTTAWrapper(model, transforms)\n",
        "\n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    predict_list = []\n",
        "\n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "    for step, images in bar:\n",
        "        images = images.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = tta_model(images)\n",
        "            #出力にソフトマックス関数を適用\n",
        "            predicts = outputs.softmax(dim=1)\n",
        "\n",
        "        predicts = predicts.cpu().detach().numpy()\n",
        "        predict_list.append(predicts)\n",
        "    predict_list = np.concatenate(predict_list, axis=0)\n",
        "    #予測値が1である確率を提出します。\n",
        "    predict_list = predict_list[:, 1]\n",
        "    gc.collect()\n",
        "\n",
        "    return predict_list"
      ],
      "metadata": {
        "id": "gICyRtmjQEU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(model_paths, dataloader, device):\n",
        "    final_preds = []\n",
        "    for i, path in enumerate(model_paths):\n",
        "        model = create_model(ARGS)\n",
        "        model = model.to(device)\n",
        "\n",
        "        #学習済みモデルの読み込み\n",
        "        model.load_state_dict(torch.load(path))\n",
        "        model.eval()\n",
        "\n",
        "        print(f\"Getting predictions for model {i+1}\")\n",
        "        preds = valid_fn(model, dataloader, device)\n",
        "        final_preds.append(preds)\n",
        "\n",
        "    final_preds = np.array(final_preds)\n",
        "    final_preds = np.mean(final_preds, axis=0)\n",
        "    return final_preds"
      ],
      "metadata": {
        "id": "HIlgSShwby7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATHS = [\n",
        "    f\"{ARGS['OUT_DIR']}/Score-Fold-{i}.bin\" for i in range(ARGS[\"n_fold\"])\n",
        "]\n",
        "\n",
        "predict_list = inference(MODEL_PATHS, test_loader, ARGS[\"device\"])\n",
        "submit[1] = predict_list\n",
        "submit.head()"
      ],
      "metadata": {
        "id": "jNGBr9KFbnyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit.to_csv(f\"{ARGS['OUT_DIR']}/submission_swin_CV{scores:.4f}.csv\", index=False, header=None)"
      ],
      "metadata": {
        "id": "FJBtrDVEbomS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "vit = pd.read_csv('drive/MyDrive/DataCompetition/TECHNOPRO/submission_vit_CV0.95.csv', names=['id', 'y'])\n",
        "vit2 = pd.read_csv('drive/MyDrive/DataCompetition/TECHNOPRO/submission_vit_CV0.9267.csv', names=['id', 'y'])\n",
        "swin = pd.read_csv('drive/MyDrive/DataCompetition/TECHNOPRO/submission_swin_384_CV0.9280.csv', names=['id', 'y'])\n",
        "swin2 = pd.read_csv('drive/MyDrive/DataCompetition/TECHNOPRO/submission_mix4.csv', names=['id', 'y'])\n",
        "sample = pd.read_csv('drive/MyDrive/DataCompetition/TECHNOPRO/dataset/sample_submit.csv', names=['id', 'y'])\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df['id'] = sample['id']\n",
        "df['vit'] = vit['y']\n",
        "df['vit2'] = vit2['y']\n",
        "df['swin'] = swin['y']\n",
        "df['swin2'] = swin2['y']\n",
        "df['mix'] = df['vit']*0.8 + df['swin2']*0.2\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df[['vit', 'swin', 'mix']], bins=40, edgecolor='black')\n",
        "plt.xlabel('Values')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Data')\n",
        "plt.show()\n",
        "df[['id', 'mix']].to_csv('drive/MyDrive/DataCompetition/TECHNOPRO/submission_vit_mix.csv', header=None, index=None)"
      ],
      "metadata": {
        "id": "P6Aefy6KRCZD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "3f0ff099-8c50-4e5f-9d3a-5b6897d983cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ou1RSNHr34nD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}